{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 1\n",
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 'love'), (5, 'you'), (3, 'can'), (2, 'what'), (2, 'teaching'), (2, 'not'), (2, 'else'), (2, 'do'), (2, 'I'), (1, 'which'), (1, 'to'), (1, 'the'), (1, 'something'), (1, 'if'), (1, 'give'), (1, 'develop'), (1, 'capabilities'), (1, 'application'), (1, 'an'), (1, 'all'), (1, 'Python'), (1, 'If')]\n",
      "The most frequent word is love.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "paragraph = 'I love teaching. If you do not love teaching what else can you love. I love Python if you do not love something which can give you all the capabilities to develop an application what else can you love.'\n",
    "paragraph = re.sub(r'[.]', '', paragraph)\n",
    "split = re.split(' ', paragraph)\n",
    "count = []\n",
    "for i in split:\n",
    "    if (split.count(i), i) not in count:\n",
    "        count.append((split.count(i), i))\n",
    "s_count = sorted(count, reverse=True)        \n",
    "print(s_count)\n",
    "print(f'The most frequent word is {s_count[0][1]}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points = ['-1', '2', '-4', '-3', '-1', '0', '4', '8']\n",
      "sorted_points = [-4, -3, -1, -1, 0, 2, 4, 8]\n",
      "distance = 8 - (-4) # 12\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = 'The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction. Extract these numbers from this whole text and find the distance between the two furthest particles.'\n",
    "points = re.findall(r'\\d|-\\d', text)\n",
    "int_points = [int(i) for i in points]\n",
    "sorted_points = sorted(int_points)\n",
    "distance = sorted_points[-1] - sorted_points[0]\n",
    "print(f'points = {points}')\n",
    "print(f'sorted_points = {sorted_points}')\n",
    "print(f'distance = {sorted_points[-1]} - ({sorted_points[0]}) # {distance}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 2\n",
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_valid_variable(variable):\n",
    "    if re.findall(r'^[0-9]', variable) or re.findall(r'-', variable):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "print(is_valid_variable('first_name')) # True\n",
    "print(is_valid_variable('first-name')) # False\n",
    "print(is_valid_variable('1first_name')) # False\n",
    "print(is_valid_variable('firstname')) # True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 3\n",
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a teacher and I love teaching There is nothing as more rewarding as educating and empowering people I found teaching more interesting than any other jobs Does this motivate you to be a teacher\n",
      "[(3, 'I'), (2, 'teaching'), (2, 'teacher')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''\n",
    "clean_text = re.sub(r'[%$@,&#;.!?]', '', sentence)\n",
    "print(clean_text)\n",
    "\n",
    "def most_frequent_words(txt):\n",
    "    split = re.split(' ', txt)\n",
    "    count = []\n",
    "    for i in split:\n",
    "        if (split.count(i), i) not in count:\n",
    "            count.append((split.count(i), i))\n",
    "    s_count = sorted(count, reverse=True)\n",
    "    return s_count[0 : 3]\n",
    "print(most_frequent_words(clean_text))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
